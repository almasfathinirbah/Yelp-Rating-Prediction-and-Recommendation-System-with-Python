{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Data Preparation**","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport string\nimport json\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom nltk.tokenize import WordPunctTokenizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import sparse\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\n\nimport collections\nimport re, string\nimport sys\nimport time\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\n#from mpl_toolkits.basemap import Basemap\n\nfrom subprocess import check_output\n%matplotlib inline\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, GRU\nfrom keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.metrics import max_error\nfrom math import sqrt\n\nfrom sklearn.metrics import mean_squared_error, max_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score,roc_curve  # classification metrics","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:44:34.851825Z","iopub.execute_input":"2021-10-12T22:44:34.852265Z","iopub.status.idle":"2021-10-12T22:44:41.858374Z","shell.execute_reply.started":"2021-10-12T22:44:34.852167Z","shell.execute_reply":"2021-10-12T22:44:41.857557Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df_yelp_business = pd.read_json('../input/yelp-dataset/yelp_academic_dataset_business.json', lines=True)\ndf_yelp_business.fillna('NA', inplace=True)\n\nprint('Final businesses shape: ', df_yelp_business.shape)\ndf_yelp_business.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:44:41.859625Z","iopub.execute_input":"2021-10-12T22:44:41.860073Z","iopub.status.idle":"2021-10-12T22:44:49.577488Z","shell.execute_reply.started":"2021-10-12T22:44:41.860027Z","shell.execute_reply":"2021-10-12T22:44:49.576398Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_yelp_review_iter = pd.read_json('../input/yelp-dataset/yelp_academic_dataset_review.json', chunksize=100000, lines=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:44:49.579011Z","iopub.execute_input":"2021-10-12T22:44:49.579322Z","iopub.status.idle":"2021-10-12T22:44:49.589429Z","shell.execute_reply.started":"2021-10-12T22:44:49.579275Z","shell.execute_reply":"2021-10-12T22:44:49.588394Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_yelp_review = pd.DataFrame()\ni=0\nfor df in df_yelp_review_iter:\n    df = df[df['business_id'].isin(df_yelp_business['business_id'])]\n    df_yelp_review = pd.concat([df_yelp_review, df])\n    i=i+1\n    print(i)\n    if i==7: break","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:44:49.591053Z","iopub.execute_input":"2021-10-12T22:44:49.591388Z","iopub.status.idle":"2021-10-12T22:45:11.117734Z","shell.execute_reply.started":"2021-10-12T22:44:49.591346Z","shell.execute_reply":"2021-10-12T22:45:11.116586Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_yelp_business = df_yelp_business[df_yelp_business['business_id'].isin(df_yelp_review['business_id'])]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:45:11.119059Z","iopub.execute_input":"2021-10-12T22:45:11.119390Z","iopub.status.idle":"2021-10-12T22:45:11.394678Z","shell.execute_reply.started":"2021-10-12T22:45:11.119358Z","shell.execute_reply":"2021-10-12T22:45:11.393711Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print('Final businesses shape: ', df_yelp_business.shape)\nprint('Final review shape: ', df_yelp_review.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:45:11.396417Z","iopub.execute_input":"2021-10-12T22:45:11.396818Z","iopub.status.idle":"2021-10-12T22:45:11.403123Z","shell.execute_reply.started":"2021-10-12T22:45:11.396773Z","shell.execute_reply":"2021-10-12T22:45:11.401947Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    ## Remove puncuation\n    text = text.translate(string.punctuation)\n    \n    ## Convert words to lower case and split them\n    text = text.lower().split()\n    \n    ## Remove stop words\n    stops = set(stopwords.words(\"english\"))\n    text = [w for w in text if not w in stops and len(w) >= 3]\n    \n    text = \" \".join(text)\n    \n    # Clean the text\n    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\",\", \" \", text)\n    text = re.sub(r\"\\.\", \" \", text)\n    text = re.sub(r\"!\", \" ! \", text)\n    text = re.sub(r\"\\/\", \" \", text)\n    text = re.sub(r\"\\^\", \" ^ \", text)\n    text = re.sub(r\"\\+\", \" + \", text)\n    text = re.sub(r\"\\-\", \" - \", text)\n    text = re.sub(r\"\\=\", \" = \", text)\n    text = re.sub(r\"'\", \" \", text)\n    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n    text = re.sub(r\":\", \" : \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\" u s \", \" american \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e - mail\", \"email\", text)\n    text = re.sub(r\"j k\", \"jk\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)    \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:45:11.404811Z","iopub.execute_input":"2021-10-12T22:45:11.405227Z","iopub.status.idle":"2021-10-12T22:45:11.419941Z","shell.execute_reply.started":"2021-10-12T22:45:11.405164Z","shell.execute_reply":"2021-10-12T22:45:11.418880Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_yelp_review['text'] = df_yelp_review['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:45:11.423491Z","iopub.execute_input":"2021-10-12T22:45:11.423931Z","iopub.status.idle":"2021-10-12T22:49:04.479128Z","shell.execute_reply.started":"2021-10-12T22:45:11.423885Z","shell.execute_reply":"2021-10-12T22:49:04.478173Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"vectorizer_reviews = CountVectorizer(min_df = .01,max_df = .99, tokenizer = WordPunctTokenizer().tokenize)\nvectorized_reviews = vectorizer_reviews.fit_transform(df_yelp_review['text'])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:49:04.482958Z","iopub.execute_input":"2021-10-12T22:49:04.483390Z","iopub.status.idle":"2021-10-12T22:50:01.370630Z","shell.execute_reply.started":"2021-10-12T22:49:04.483347Z","shell.execute_reply":"2021-10-12T22:50:01.369719Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(vectorized_reviews.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:50:01.371882Z","iopub.execute_input":"2021-10-12T22:50:01.372357Z","iopub.status.idle":"2021-10-12T22:50:01.377664Z","shell.execute_reply.started":"2021-10-12T22:50:01.372312Z","shell.execute_reply":"2021-10-12T22:50:01.376702Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"' | '.join(vectorizer_reviews.get_feature_names()[:100]) # only the first 100","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:50:01.379092Z","iopub.execute_input":"2021-10-12T22:50:01.379418Z","iopub.status.idle":"2021-10-12T22:50:01.391392Z","shell.execute_reply.started":"2021-10-12T22:50:01.379387Z","shell.execute_reply":"2021-10-12T22:50:01.390362Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"vectorizer_categories = CountVectorizer(min_df = 1, max_df = 1., tokenizer = lambda x: x.split(', '))\nvectorized_categories = vectorizer_categories.fit_transform(df_yelp_business['categories'])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:50:01.392818Z","iopub.execute_input":"2021-10-12T22:50:01.393175Z","iopub.status.idle":"2021-10-12T22:50:01.524057Z","shell.execute_reply.started":"2021-10-12T22:50:01.393146Z","shell.execute_reply":"2021-10-12T22:50:01.523158Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(vectorized_categories.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:50:01.525541Z","iopub.execute_input":"2021-10-12T22:50:01.525818Z","iopub.status.idle":"2021-10-12T22:50:01.531270Z","shell.execute_reply.started":"2021-10-12T22:50:01.525790Z","shell.execute_reply":"2021-10-12T22:50:01.530258Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"' | '.join(vectorizer_categories.get_feature_names()[:100]) # only the first 100","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:50:01.532633Z","iopub.execute_input":"2021-10-12T22:50:01.532920Z","iopub.status.idle":"2021-10-12T22:50:01.543811Z","shell.execute_reply.started":"2021-10-12T22:50:01.532894Z","shell.execute_reply":"2021-10-12T22:50:01.542762Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom scipy import sparse\nbusinessxreview = sparse.csr_matrix(pd.get_dummies(df_yelp_review['business_id']).values)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:50:01.545085Z","iopub.execute_input":"2021-10-12T22:50:01.545399Z","iopub.status.idle":"2021-10-12T22:51:15.274432Z","shell.execute_reply.started":"2021-10-12T22:50:01.545370Z","shell.execute_reply":"2021-10-12T22:51:15.273128Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom scipy import sparse\nbusinessxreview = sparse.csr_matrix(pd.get_dummies(df_yelp_review['business_id']).values)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:51:15.276194Z","iopub.execute_input":"2021-10-12T22:51:15.276644Z","iopub.status.idle":"2021-10-12T22:52:26.921960Z","shell.execute_reply.started":"2021-10-12T22:51:15.276599Z","shell.execute_reply":"2021-10-12T22:52:26.920781Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print('restaurants x categories: \\t', vectorized_categories.shape) \nprint('restaurants x reviews: \\t\\t' , businessxreview.shape) \nprint('reviews x words: \\t\\t', vectorized_reviews.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:52:26.923605Z","iopub.execute_input":"2021-10-12T22:52:26.924207Z","iopub.status.idle":"2021-10-12T22:52:26.931477Z","shell.execute_reply.started":"2021-10-12T22:52:26.924160Z","shell.execute_reply":"2021-10-12T22:52:26.930421Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_yelp_tips = pd.read_json('../input/yelp-dataset/yelp_academic_dataset_tip.json', lines=True)\ndf_yelp_tips.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:52:26.932816Z","iopub.execute_input":"2021-10-12T22:52:26.933120Z","iopub.status.idle":"2021-10-12T22:52:40.349570Z","shell.execute_reply.started":"2021-10-12T22:52:26.933081Z","shell.execute_reply":"2021-10-12T22:52:40.348477Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df_yelp_user_iter = pd.read_json('../input/yelp-dataset/yelp_academic_dataset_user.json', chunksize=100000, lines=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:52:40.351232Z","iopub.execute_input":"2021-10-12T22:52:40.351673Z","iopub.status.idle":"2021-10-12T22:52:40.371404Z","shell.execute_reply.started":"2021-10-12T22:52:40.351629Z","shell.execute_reply":"2021-10-12T22:52:40.370258Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df_yelp_user = pd.DataFrame()\ni=0\nfor df in df_yelp_user_iter:\n    df = df[df['user_id'].isin(df_yelp_review['user_id'])]\n    df_yelp_user = pd.concat([df_yelp_user, df])\n    i=i+1\n    print(i)\n    if i==7: break","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:52:40.373235Z","iopub.execute_input":"2021-10-12T22:52:40.373670Z","iopub.status.idle":"2021-10-12T22:53:34.391499Z","shell.execute_reply.started":"2021-10-12T22:52:40.373627Z","shell.execute_reply":"2021-10-12T22:53:34.390408Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(df_yelp_business.shape)\nprint(df_yelp_business.columns)\ndf_yelp_business.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:34.393082Z","iopub.execute_input":"2021-10-12T22:53:34.393582Z","iopub.status.idle":"2021-10-12T22:53:34.434708Z","shell.execute_reply.started":"2021-10-12T22:53:34.393536Z","shell.execute_reply":"2021-10-12T22:53:34.433595Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(df_yelp_review.shape)\nprint(df_yelp_review.columns)\ndf_yelp_review.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:34.436357Z","iopub.execute_input":"2021-10-12T22:53:34.436774Z","iopub.status.idle":"2021-10-12T22:53:34.460567Z","shell.execute_reply.started":"2021-10-12T22:53:34.436730Z","shell.execute_reply":"2021-10-12T22:53:34.459433Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(df_yelp_user.shape)\nprint(df_yelp_user.columns)\ndf_yelp_user.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:34.549893Z","iopub.execute_input":"2021-10-12T22:53:34.550314Z","iopub.status.idle":"2021-10-12T22:53:34.591146Z","shell.execute_reply.started":"2021-10-12T22:53:34.550256Z","shell.execute_reply":"2021-10-12T22:53:34.590217Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(df_yelp_tips.shape)\nprint(df_yelp_tips.columns)\ndf_yelp_tips.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:34.592966Z","iopub.execute_input":"2021-10-12T22:53:34.593286Z","iopub.status.idle":"2021-10-12T22:53:34.609839Z","shell.execute_reply.started":"2021-10-12T22:53:34.593257Z","shell.execute_reply":"2021-10-12T22:53:34.608694Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## **Handle Missing Data**","metadata":{}},{"cell_type":"code","source":"# simple data checking - get row and column of dataframe\nprint('simple data checking of yelp_business: ',df_yelp_business.shape, df_yelp_business.columns)\nprint('simple data checking of yelp_review: ',df_yelp_review.shape, df_yelp_review.columns)\nprint('simple data checking of yelp_tips: ',df_yelp_tips.shape, df_yelp_tips.columns)\nprint('simple data checking of yelp_user: ',df_yelp_user.shape, df_yelp_user.columns)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:34.611556Z","iopub.execute_input":"2021-10-12T22:53:34.611920Z","iopub.status.idle":"2021-10-12T22:53:34.623193Z","shell.execute_reply.started":"2021-10-12T22:53:34.611889Z","shell.execute_reply":"2021-10-12T22:53:34.622120Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# check standard missing value - multiple column\nmissing_data = df_yelp_business.isnull()\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")  ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:34.625245Z","iopub.execute_input":"2021-10-12T22:53:34.625530Z","iopub.status.idle":"2021-10-12T22:53:34.694017Z","shell.execute_reply.started":"2021-10-12T22:53:34.625502Z","shell.execute_reply":"2021-10-12T22:53:34.693026Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# check standard missing value - multiple column\nmissing_data = df_yelp_review.isnull()\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")  ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:34.695189Z","iopub.execute_input":"2021-10-12T22:53:34.695529Z","iopub.status.idle":"2021-10-12T22:53:35.165856Z","shell.execute_reply.started":"2021-10-12T22:53:34.695498Z","shell.execute_reply":"2021-10-12T22:53:35.164807Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# check standard missing value - multiple column\nmissing_data = df_yelp_tips.isnull()\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")  ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:35.167588Z","iopub.execute_input":"2021-10-12T22:53:35.167861Z","iopub.status.idle":"2021-10-12T22:53:35.657985Z","shell.execute_reply.started":"2021-10-12T22:53:35.167833Z","shell.execute_reply":"2021-10-12T22:53:35.656815Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# check standard missing value - multiple column\nmissing_data = df_yelp_user.isnull()\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")  ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:35.659220Z","iopub.execute_input":"2021-10-12T22:53:35.659514Z","iopub.status.idle":"2021-10-12T22:53:36.092370Z","shell.execute_reply.started":"2021-10-12T22:53:35.659485Z","shell.execute_reply":"2021-10-12T22:53:36.091345Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## **Handle Date Column**","metadata":{}},{"cell_type":"code","source":"# simple data checking - check 1 of the date column\ndf_yelp_review['date'].head(15)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.094497Z","iopub.execute_input":"2021-10-12T22:53:36.094880Z","iopub.status.idle":"2021-10-12T22:53:36.103867Z","shell.execute_reply.started":"2021-10-12T22:53:36.094846Z","shell.execute_reply":"2021-10-12T22:53:36.102453Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_yelp_review[\"date\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.106257Z","iopub.execute_input":"2021-10-12T22:53:36.106764Z","iopub.status.idle":"2021-10-12T22:53:36.186723Z","shell.execute_reply.started":"2021-10-12T22:53:36.106721Z","shell.execute_reply":"2021-10-12T22:53:36.185710Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# change to date type & change date format\nseries_date_in_date = pd.to_datetime(df_yelp_review[\"date\"],errors='raise',dayfirst=False,yearfirst=True,utc=True)\nseries_date_in_date","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.187927Z","iopub.execute_input":"2021-10-12T22:53:36.188215Z","iopub.status.idle":"2021-10-12T22:53:36.220333Z","shell.execute_reply.started":"2021-10-12T22:53:36.188186Z","shell.execute_reply":"2021-10-12T22:53:36.219319Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# parsing date column\nseries_date_in_date = pd.to_datetime(df_yelp_review[\"date\"],errors='raise',dayfirst=False,yearfirst=True,utc=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.221808Z","iopub.execute_input":"2021-10-12T22:53:36.222093Z","iopub.status.idle":"2021-10-12T22:53:36.241684Z","shell.execute_reply.started":"2021-10-12T22:53:36.222066Z","shell.execute_reply":"2021-10-12T22:53:36.240688Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"series_date_in_date.dt.day","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.243938Z","iopub.execute_input":"2021-10-12T22:53:36.244329Z","iopub.status.idle":"2021-10-12T22:53:36.338038Z","shell.execute_reply.started":"2021-10-12T22:53:36.244273Z","shell.execute_reply":"2021-10-12T22:53:36.337001Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"series_date_in_date.dt.month","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.339516Z","iopub.execute_input":"2021-10-12T22:53:36.339847Z","iopub.status.idle":"2021-10-12T22:53:36.428191Z","shell.execute_reply.started":"2021-10-12T22:53:36.339816Z","shell.execute_reply":"2021-10-12T22:53:36.427160Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_yelp_review[\"year\"] = series_date_in_date.dt.year","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.429347Z","iopub.execute_input":"2021-10-12T22:53:36.429620Z","iopub.status.idle":"2021-10-12T22:53:36.516793Z","shell.execute_reply.started":"2021-10-12T22:53:36.429594Z","shell.execute_reply":"2021-10-12T22:53:36.515673Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis (EDA)**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.basemap import Basemap\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.517965Z","iopub.execute_input":"2021-10-12T22:53:36.518248Z","iopub.status.idle":"2021-10-12T22:53:36.853770Z","shell.execute_reply.started":"2021-10-12T22:53:36.518221Z","shell.execute_reply":"2021-10-12T22:53:36.852772Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## **Overview of reviews**","metadata":{}},{"cell_type":"code","source":"useful_reviews = len(df_yelp_review[df_yelp_review[\"useful\"]>0])\ncool_reviews = len(df_yelp_review[df_yelp_review[\"cool\"]>0])\nfunny_reviews = len(df_yelp_review[df_yelp_review[\"funny\"]>0])\nnegative_reviws = len(df_yelp_review[df_yelp_review[\"stars\"]<2])\npositive_reviews =len(df_yelp_review[df_yelp_review[\"stars\"]>3])\ntotal_reviews = len(df_yelp_review)\n\nprint(\"Total reviews: {}\".format(total_reviews))\nprint(\"Useful reviews: {}\".format(useful_reviews))\nprint(\"Funny reviews: {}\".format(funny_reviews))\nprint(\"Cool reviews: {}\".format(cool_reviews))\nprint(\"Total negative reviews: {}\".format(negative_reviws))\nprint(\"Total positive reviews: {}\".format(positive_reviews))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:36.855591Z","iopub.execute_input":"2021-10-12T22:53:36.855863Z","iopub.status.idle":"2021-10-12T22:53:37.316790Z","shell.execute_reply.started":"2021-10-12T22:53:36.855836Z","shell.execute_reply":"2021-10-12T22:53:37.315703Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## **Top reviewed business**","metadata":{}},{"cell_type":"code","source":"top_reviewed = df_yelp_review[df_yelp_review[\"stars\"]>3]\ntop_reviews_dict ={}\n\nfor business_id in top_reviewed[\"business_id\"].values:\n    try :\n        top_reviews_dict[business_id] =top_reviews_dict[business_id]+1\n    except:\n        top_reviews_dict[business_id]=1\n        \ntopbusiness = pd.DataFrame.from_dict(data= top_reviews_dict,orient=\"index\")\n\ntopbusiness.reset_index(inplace=True)\ntopbusiness.columns = ['business_id', 'rated']\ndel(top_reviews_dict)\ndel(top_reviewed)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:37.317939Z","iopub.execute_input":"2021-10-12T22:53:37.318209Z","iopub.status.idle":"2021-10-12T22:53:37.666836Z","shell.execute_reply.started":"2021-10-12T22:53:37.318182Z","shell.execute_reply":"2021-10-12T22:53:37.665840Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"top_count= 20\nright=pd.DataFrame(df_yelp_business[['business_id',\"name\",\"categories\"]].values,\n                    columns=['business_id',\"Business name\",\"categories\"])\n\ntop_business_data = pd.merge(topbusiness,right=right, how=\"inner\",on='business_id')\ntop_business_data.sort_values(\"rated\")[::-1][:top_count].plot(x=\"Business name\",y=\"rated\", \n                                                   kind=\"bar\",figsize=(14,6),\n                                                   title='Positive reviews').set_ylabel(\"Total ratings\")\n\ndel(topbusiness)\ndel(right)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:37.668133Z","iopub.execute_input":"2021-10-12T22:53:37.668431Z","iopub.status.idle":"2021-10-12T22:53:38.164041Z","shell.execute_reply.started":"2021-10-12T22:53:37.668402Z","shell.execute_reply":"2021-10-12T22:53:38.162895Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## **What are the locations of top reviewed businesses**\nGenerally customers are eager to know what are the locations of best business outlets etc. In this section we will find locations of top best reviwed business locations and show in map.","metadata":{}},{"cell_type":"code","source":"num_business = 300\nbusiness_ids = top_business_data.sort_values(\"rated\")[::-1][:num_business].business_id.values\n#len(business_ids)\nuseful_b = df_yelp_business.loc[df_yelp_business['business_id'].isin(business_ids)]\n\n#len(useful_b)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:38.165815Z","iopub.execute_input":"2021-10-12T22:53:38.166249Z","iopub.status.idle":"2021-10-12T22:53:38.182589Z","shell.execute_reply.started":"2021-10-12T22:53:38.166205Z","shell.execute_reply":"2021-10-12T22:53:38.181568Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(14, 8), edgecolor='w')\n\nm = Basemap(projection='cyl',llcrnrlon= -180, urcrnrlon = 180,\n            llcrnrlat = -90, urcrnrlat= 90,resolution='c',\n           lat_ts = True)\nm.drawcoastlines()\nm.fillcontinents(color='#bbdaa4',lake_color='#FFFFFF')\nm.drawcountries()\nm.drawmapboundary(fill_color='#FFFFFF')\n\nmloc = m(useful_b['latitude'].tolist(),useful_b['longitude'].tolist())\nm.scatter(mloc[1],mloc[0],color ='red',lw=3,alpha=0.3,zorder=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:38.185380Z","iopub.execute_input":"2021-10-12T22:53:38.186640Z","iopub.status.idle":"2021-10-12T22:53:38.893134Z","shell.execute_reply.started":"2021-10-12T22:53:38.186593Z","shell.execute_reply":"2021-10-12T22:53:38.892371Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## **How businesses are getting reviewed over time**\nSome businesses try to maintain their overall quality standards and make their customers happy. Lets see which businesses are maintaining their quality standards based on positive reviews.","metadata":{}},{"cell_type":"code","source":"num_business = 3\nbusiness_ids = top_business_data.sort_values(\"rated\")[::-1][:num_business].business_id.values\nbusiness_names = top_business_data.sort_values(\"rated\")[::-1][:num_business][\"Business name\"].values\nfor i, business_id in enumerate(business_ids):\n    useful_b = df_yelp_review.loc[df_yelp_review['business_id'] == business_id]\n    useful_b = useful_b.groupby(['year']).size().reset_index(name='counts')\n    #print(useful_b.head())\n    series = pd.Series(useful_b[\"counts\"].values, index=useful_b[\"year\"].values, name='Review trend')\n    axes = series.plot(kind=\"bar\",figsize=(10, 7))\n    plt.xlabel('Year', axes=axes)\n    plt.ylabel('Total positive reviews', axes=axes)\n    plt.title('Review trend of {}'.format(business_names[i]), axes=axes)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:38.900605Z","iopub.execute_input":"2021-10-12T22:53:38.901148Z","iopub.status.idle":"2021-10-12T22:53:39.890939Z","shell.execute_reply.started":"2021-10-12T22:53:38.901094Z","shell.execute_reply":"2021-10-12T22:53:39.890277Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## **Most recent Trending businesses**","metadata":{}},{"cell_type":"code","source":"top_business = 3\ntemp = df_yelp_review[[\"business_id\",'year',\"stars\"]]\nfive_star_reviews = temp[temp[\"stars\"]>4]\ntrending_business_reviews = five_star_reviews.groupby([\"business_id\",'year']).size().reset_index(name='counts')\n\ntrending = trending_business_reviews.sort_values(['year','counts'])[::-1][:top_business].business_id.values\nfor  business_id in trending:\n    record = trending_business_reviews.loc[trending_business_reviews['business_id'] == business_id]\n    business_name = df_yelp_business.loc[df_yelp_business['business_id'] == business_id].name.values\n    series = pd.Series(record[\"counts\"].values, index=record.year.values, name='Trending business')\n    axes = series.plot(kind=\"bar\",figsize=(10, 7))\n    plt.xlabel('Year', axes=axes)\n    plt.ylabel('Total positive reviews', axes=axes)\n    plt.title('Review trend of {}'.format(business_name), axes=axes)\n    plt.show()\n    #len(trending_business_reviews)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:39.896035Z","iopub.execute_input":"2021-10-12T22:53:39.896319Z","iopub.status.idle":"2021-10-12T22:53:40.872264Z","shell.execute_reply.started":"2021-10-12T22:53:39.896277Z","shell.execute_reply":"2021-10-12T22:53:40.871376Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## **Categories of top reviewed businesses**","metadata":{}},{"cell_type":"code","source":"num_cat =10 # to show top 10 catrgories\ntop_business = 30 # choose categories of top 30 businesses\ncat_data = top_business_data.sort_values(\"rated\")[::-1][:top_business]\n#cat_data.categories\nCategories={}\nfor cat in cat_data.categories.values:\n    all_categories= cat.split(\",\")\n    for x in all_categories:\n        try :\n            Categories[x] =Categories[x]+1\n        except:\n            Categories[x]=1\ntop_categories = pd.DataFrame.from_dict(data= Categories,orient=\"index\")\ntop_categories.reset_index(inplace=True)\ntop_categories.columns = ['category', 'occurance']\n\nx_val=top_categories.sort_values(\"occurance\")[::-1][:num_cat].occurance.values\nlabels=top_categories.sort_values(\"occurance\")[::-1][:num_cat].category.values\nseries = pd.Series(x_val, index=labels, name='Top business types')\nseries.plot.pie(figsize=(10, 10),startangle=90)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:40.873550Z","iopub.execute_input":"2021-10-12T22:53:40.873817Z","iopub.status.idle":"2021-10-12T22:53:41.069675Z","shell.execute_reply.started":"2021-10-12T22:53:40.873790Z","shell.execute_reply":"2021-10-12T22:53:41.068722Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## **Categories of trending businesses**","metadata":{}},{"cell_type":"code","source":"num_cat =10 # to show top 10 catrgories\ntop_business = 40 # choose categories of top 30 businesses\nbusiness_ids = trending_business_reviews.sort_values(['year','counts'])[::-1][:top_business].business_id.values\ncat_data = top_business_data.loc[top_business_data['business_id'].isin(business_ids)]\n#cat_data.categories\nCategories={}\nfor cat in cat_data.categories.values:\n    all_categories= cat.split(\",\")\n    for x in all_categories:\n        try :\n            Categories[x] =Categories[x]+1\n        except:\n            Categories[x]=1\ntop_categories = pd.DataFrame.from_dict(data= Categories,orient=\"index\")\ntop_categories.reset_index(inplace=True)\ntop_categories.columns = ['category', 'occurance']\n\nx_val=top_categories.sort_values(\"occurance\")[::-1][:num_cat].occurance.values\nlabels=top_categories.sort_values(\"occurance\")[::-1][:num_cat].category.values\nseries = pd.Series(x_val, index=labels, name='Trending business types')\nseries.plot.pie(figsize=(10, 10),startangle=90)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T23:38:20.122185Z","iopub.execute_input":"2021-10-12T23:38:20.122508Z","iopub.status.idle":"2021-10-12T23:38:20.348644Z","shell.execute_reply.started":"2021-10-12T23:38:20.122478Z","shell.execute_reply":"2021-10-12T23:38:20.347473Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"## **Negatively reviewed businesses**","metadata":{}},{"cell_type":"code","source":"bottom_reviewed = df_yelp_review[df_yelp_review[\"stars\"]<2]\nbottom_reviews_dict ={} \n\nfor business_id in bottom_reviewed[\"business_id\"].values:\n    try :\n        bottom_reviews_dict[business_id] =bottom_reviews_dict[business_id]+1\n    except:\n        bottom_reviews_dict[business_id]=1\n        \nbottombusiness = pd.DataFrame.from_dict(data= bottom_reviews_dict,orient=\"index\")\n\nbottombusiness.reset_index(inplace=True)\n#bottombusiness.head()\nbottombusiness.columns = ['business_id', 'rated']","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:41.287566Z","iopub.execute_input":"2021-10-12T22:53:41.287991Z","iopub.status.idle":"2021-10-12T22:53:41.394787Z","shell.execute_reply.started":"2021-10-12T22:53:41.287945Z","shell.execute_reply":"2021-10-12T22:53:41.393678Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"top_count= 20\nright=pd.DataFrame(df_yelp_business[['business_id',\"name\",\"categories\"]].values,\n                    columns=['business_id',\"Business name\",\"categories\"])\n\nbottom_business_data = pd.merge(bottombusiness,right=right, how=\"inner\",on='business_id')\nbottom_business_data.sort_values(\"rated\")[::-1][:top_count].plot(x=\"Business name\",y=\"rated\", \n                                                   kind=\"bar\",figsize=(14,6),\n                                                   title='Negative reviews').set_ylabel(\"Total 1 star ratings\")\n\ndel(bottom_reviewed)\ndel(bottom_reviews_dict)\ndel(bottombusiness)\ndel(right)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:41.396224Z","iopub.execute_input":"2021-10-12T22:53:41.396677Z","iopub.status.idle":"2021-10-12T22:53:41.830425Z","shell.execute_reply.started":"2021-10-12T22:53:41.396644Z","shell.execute_reply":"2021-10-12T22:53:41.829411Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## **Business categories which needs improvement**","metadata":{}},{"cell_type":"code","source":"num_cat =10 # to show top 10 catrgories\nbottom_business = 30 # choose categories of top 30 businesses\ncat_data = bottom_business_data.sort_values(\"rated\")[::-1][:bottom_business]\n\nCategories={}\nfor cat in cat_data.categories.values:\n    all_categories= cat.split(\",\")\n    for x in all_categories:\n        try :\n            Categories[x] =Categories[x]+1\n        except:\n            Categories[x]=1\nbottom_categories = pd.DataFrame.from_dict(data= Categories,orient=\"index\")\nbottom_categories.reset_index(inplace=True)\nbottom_categories.columns = ['category', 'occurance']\n\nx_val=bottom_categories.sort_values(\"occurance\")[::-1][:num_cat].occurance.values\nlabels=bottom_categories.sort_values(\"occurance\")[::-1][:num_cat].category.values\nseries = pd.Series(x_val, index=labels, name='Categories')\nseries.plot.pie(figsize=(10, 10),startangle=90)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:41.831901Z","iopub.execute_input":"2021-10-12T22:53:41.832245Z","iopub.status.idle":"2021-10-12T22:53:42.034634Z","shell.execute_reply.started":"2021-10-12T22:53:41.832212Z","shell.execute_reply":"2021-10-12T22:53:42.033625Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## **Most frequent words in Positive and Negative reviews**","metadata":{}},{"cell_type":"code","source":"import collections\nfrom wordcloud import WordCloud","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:42.035937Z","iopub.execute_input":"2021-10-12T22:53:42.036396Z","iopub.status.idle":"2021-10-12T22:53:42.041285Z","shell.execute_reply.started":"2021-10-12T22:53:42.036351Z","shell.execute_reply":"2021-10-12T22:53:42.040481Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# these are helper functions \n# directly copied from https://gist.github.com/benhoyt/dfafeab26d7c02a52ed17b6229f0cb52\n\ndef tokenize(s):\n    \"\"\"Convert string to lowercase and split into words (ignoring\n    punctuation), returning list of words.\n    \"\"\"\n    word_list = re.findall(r'\\w+', s.lower())\n    filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n    return filtered_words\n\n\ndef count_ngrams(lines, min_length=2, max_length=4):\n    \"\"\"Iterate through given lines iterator (file object or list of\n    lines) and return n-gram frequencies. The return value is a dict\n    mapping the length of the n-gram to a collections.Counter\n    object of n-gram tuple and number of times that n-gram occurred.\n    Returned dict includes n-grams of length min_length to max_length.\n    \"\"\"\n    lengths = range(min_length, max_length + 1)\n    ngrams = {length: collections.Counter() for length in lengths}\n    queue = collections.deque(maxlen=max_length)\n\n    # Helper function to add n-grams at start of current queue to dict\n    def add_queue():\n        current = tuple(queue)\n        for length in lengths:\n            if len(current) >= length:\n                ngrams[length][current[:length]] += 1\n\n    # Loop through all lines and words and add n-grams to dict\n    for line in lines:\n        for word in tokenize(line):\n            queue.append(word)\n            if len(queue) >= max_length:\n                add_queue()\n\n    # Make sure we get the n-grams at the tail end of the queue\n    while len(queue) > min_length:\n        queue.popleft()\n        add_queue()\n\n    return ngrams\n\ndef print_most_frequent(ngrams, num=10):\n    \"\"\"Print num most common n-grams of each length in n-grams dict.\"\"\"\n    for n in sorted(ngrams):\n        print('----- {} most common {}-word phrase -----'.format(num, n))\n        for gram, count in ngrams[n].most_common(num):\n            print('{0}: {1}'.format(' '.join(gram), count))\n        print('')\n\ndef print_word_cloud(ngrams, num=5):\n    \"\"\"Print word cloud image plot \"\"\"\n    words = []\n    for n in sorted(ngrams):\n        for gram, count in ngrams[n].most_common(num):\n            s = ' '.join(gram)\n            words.append(s)\n            \n    cloud = WordCloud(width=1440, height= 1080,max_words= 200).generate(' '.join(words))\n    plt.figure(figsize=(20, 15))\n    plt.imshow(cloud)\n    plt.axis('off');\n    plt.show()\n    print('')","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:42.042503Z","iopub.execute_input":"2021-10-12T22:53:42.042850Z","iopub.status.idle":"2021-10-12T22:53:42.059635Z","shell.execute_reply.started":"2021-10-12T22:53:42.042805Z","shell.execute_reply":"2021-10-12T22:53:42.058282Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#positive review\nnum_business_analysis = 1 # basically this will tell how much computing and diverse our analysis will be\nbusiness_ids=  top_business_data.sort_values(\"rated\")[::-1][:num_business_analysis].business_id.values\nbusiness_names =   top_business_data.sort_values(\"rated\")[::-1][:num_business_analysis][\"Business name\"].values\n# get all the reviews and analyse them\n#business_names\nfor i, business_id in enumerate(business_ids):\n    # now extract reviews from reviews data\n    print(\"Analysing business: \",business_names[i])\n    reviews = df_yelp_review.loc[df_yelp_review['business_id'] == business_id].text.values\n    most_used_text = count_ngrams(reviews,max_length=3)\n    print_most_frequent(most_used_text, num=10)\n    print_word_cloud(most_used_text, 10)\n    #print (\"total reviews \",len(reviews))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:53:42.061055Z","iopub.execute_input":"2021-10-12T22:53:42.061467Z","iopub.status.idle":"2021-10-12T22:54:15.561835Z","shell.execute_reply.started":"2021-10-12T22:53:42.061391Z","shell.execute_reply":"2021-10-12T22:54:15.561077Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#negative review\nnum_business_analysis = 1 # basically this will tell how much computing and diverse our analysis will be\nbusiness_ids=bottom_business_data.sort_values(\"rated\")[::-1][:num_business_analysis].business_id.values\nbusiness_names = bottom_business_data.sort_values(\"rated\")[::-1][:num_business_analysis][\"Business name\"].values\n# get all the reviews and analyse them\n#business_names\nfor i, business_id in enumerate(business_ids):\n    # now extract reviews from reviews data\n    print(\"Analysing business: \",business_names[i])\n    reviews = df_yelp_review.loc[df_yelp_review['business_id'] == business_id].text.values\n    most_used_text = count_ngrams(reviews,max_length=3)\n    print_most_frequent(most_used_text, num=10)\n    print_word_cloud(most_used_text, 10)\n    #print (\"total reviews \",len(reviews))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:15.563031Z","iopub.execute_input":"2021-10-12T22:54:15.563499Z","iopub.status.idle":"2021-10-12T22:54:32.110407Z","shell.execute_reply.started":"2021-10-12T22:54:15.563456Z","shell.execute_reply":"2021-10-12T22:54:32.109327Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## **Most frequent tips**","metadata":{}},{"cell_type":"code","source":"num_business_analysis = 2 # basically this will tell how much computing and diverse our analysis will be\nbusiness_ids=bottom_business_data.sort_values(\"rated\")[::-1][:num_business_analysis].business_id.values\nbusiness_names = bottom_business_data.sort_values(\"rated\")[::-1][:num_business_analysis][\"Business name\"].values\n# get all the reviews and analyse them\n#business_names\nfor i, business_id in enumerate(business_ids):\n    # now extract reviews from reviews data\n    print(\"Analysing business: \",business_names[i])\n    reviews = df_yelp_tips.loc[df_yelp_tips['business_id'] == business_id].text.values\n    most_used_text = count_ngrams(reviews,max_length=4)\n    print_most_frequent(most_used_text, num=10)\n    print_word_cloud(most_used_text, 10)\n    #print (\"total reviews \",len(reviews))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:32.111738Z","iopub.execute_input":"2021-10-12T22:54:32.112035Z","iopub.status.idle":"2021-10-12T22:54:35.532721Z","shell.execute_reply.started":"2021-10-12T22:54:32.112006Z","shell.execute_reply":"2021-10-12T22:54:35.531943Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"**Relationship between users's friends and review patterns**","metadata":{}},{"cell_type":"code","source":"top_users = 15\nuser_most_reviews = df_yelp_review.groupby(['user_id']).size().reset_index(name='counts')\ntop_users_ids = user_most_reviews.sort_values(['counts'])[::-1][:top_users].user_id.values","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:35.533656Z","iopub.execute_input":"2021-10-12T22:54:35.533916Z","iopub.status.idle":"2021-10-12T22:54:37.211877Z","shell.execute_reply.started":"2021-10-12T22:54:35.533890Z","shell.execute_reply":"2021-10-12T22:54:37.210893Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"user_frnds = {}\nfor  users_id in top_users_ids:\n    \n    record = df_yelp_user.loc[df_yelp_user['user_id'] == users_id]\n    user_frnds[users_id] = {}\n    user_frnds[users_id][\"name\"]= record.name.values[0]\n    user_frnds[users_id][\"friends\"]= record.friends.values[0]\n    if record.friends is not \"None\":\n        user_frnds[users_id][\"friends_count\"]= len(record.friends.values[0].split(\",\"))\n    else:\n        user_frnds[users_id][\"friends_count\"]=0\n    user_frnds[users_id][\"review_count\"]=record.review_count.values[0]\n    user_frnds[users_id][\"fans\"]=record.fans.values[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:37.213044Z","iopub.execute_input":"2021-10-12T22:54:37.213375Z","iopub.status.idle":"2021-10-12T22:54:38.773310Z","shell.execute_reply.started":"2021-10-12T22:54:37.213339Z","shell.execute_reply":"2021-10-12T22:54:38.772354Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"user_friend_df = pd.DataFrame.from_dict(data= user_frnds,orient=\"index\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:38.774645Z","iopub.execute_input":"2021-10-12T22:54:38.774941Z","iopub.status.idle":"2021-10-12T22:54:38.781436Z","shell.execute_reply.started":"2021-10-12T22:54:38.774911Z","shell.execute_reply":"2021-10-12T22:54:38.780441Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"user_friend_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:38.782690Z","iopub.execute_input":"2021-10-12T22:54:38.782983Z","iopub.status.idle":"2021-10-12T22:54:38.800797Z","shell.execute_reply.started":"2021-10-12T22:54:38.782946Z","shell.execute_reply":"2021-10-12T22:54:38.799711Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"axes = user_friend_df.plot(x=\"name\", y=[\"review_count\", \"friends_count\", \"fans\"],\n                           kind=\"bar\",figsize=(12, 7))\nplt.xlabel('Name', axes=axes)\nplt.ylabel('Count', axes=axes)\nplt.title('Top User Review trend'.format(business_name), axes=axes)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:38.802428Z","iopub.execute_input":"2021-10-12T22:54:38.802926Z","iopub.status.idle":"2021-10-12T22:54:39.161022Z","shell.execute_reply.started":"2021-10-12T22:54:38.802881Z","shell.execute_reply":"2021-10-12T22:54:39.160352Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"**Does user's friends influence business review?**","metadata":{}},{"cell_type":"code","source":"business_rank = 4 # 0 to 9\ntemp = df_yelp_review[[\"business_id\",'year',\"stars\"]]\nfive_star_reviews = temp[temp[\"stars\"]>4]\ntrending_business_reviews = five_star_reviews.groupby([\"business_id\",'year']).size().reset_index(name='counts')\n\nbusiness_id = trending_business_reviews.sort_values(['year','counts'])[::-1][:10].business_id.values[business_rank]\nbusiness_name = df_yelp_business.loc[df_yelp_business['business_id'] == business_id].name.values[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:39.161965Z","iopub.execute_input":"2021-10-12T22:54:39.162222Z","iopub.status.idle":"2021-10-12T22:54:39.408628Z","shell.execute_reply.started":"2021-10-12T22:54:39.162195Z","shell.execute_reply":"2021-10-12T22:54:39.407639Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"user_reviws = df_yelp_review.loc[df_yelp_review['business_id']==business_id]\ntopuser_reviws = user_reviws.groupby(['user_id']).size().reset_index(name='counts')\nprint(\"Total users who gave ratings to {} are {}\".format(business_name,len(topuser_reviws)))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:39.410152Z","iopub.execute_input":"2021-10-12T22:54:39.410733Z","iopub.status.idle":"2021-10-12T22:54:39.559446Z","shell.execute_reply.started":"2021-10-12T22:54:39.410684Z","shell.execute_reply":"2021-10-12T22:54:39.558313Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"top_users = 50 #len(topuser_reviws)// 10\ntopuser_reviws = topuser_reviws.sort_values(['counts'])[::-1][:top_users]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:39.561271Z","iopub.execute_input":"2021-10-12T22:54:39.561699Z","iopub.status.idle":"2021-10-12T22:54:39.567964Z","shell.execute_reply.started":"2021-10-12T22:54:39.561655Z","shell.execute_reply":"2021-10-12T22:54:39.567225Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"%%time\n\nusers_ids = topuser_reviws.user_id.values\nusers_ids = pd.merge(topuser_reviws,right=df_yelp_user, how=\"inner\",on='user_id')\nusers_ids =users_ids [[\"name\",\"user_id\", \"friends\"]]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:39.569025Z","iopub.execute_input":"2021-10-12T22:54:39.569331Z","iopub.status.idle":"2021-10-12T22:54:40.135264Z","shell.execute_reply.started":"2021-10-12T22:54:39.569272Z","shell.execute_reply":"2021-10-12T22:54:40.134137Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"%%time\ndef calc_frnd_review(frnds, business_id, df_yelp_review):\n        frnds = frnds.split(',')\n        # count reviews\n        #frnds = yelp_users.loc[(yelp_users['user_id'].isin(frnds)) & (yelp_users[\"review_count\"]>0 )].user_id.values\n        friend_review = df_yelp_review.loc[(df_yelp_review['business_id']==business_id) &\n                                            (df_yelp_review['user_id'].isin(frnds))\n                                           ][[\"stars\",\"user_id\"]]\n        friend_review_cnt = len(friend_review.user_id.values)\n        if(friend_review_cnt>0):\n            total_stars = friend_review.stars.sum()\n        else:\n            total_stars = 0\n        return  friend_review_cnt,total_stars\n\nusers_ids[[\"frnd_count\",\"total_stars\"]]= users_ids[\"friends\"].apply(lambda frnds: pd.Series(calc_frnd_review(frnds, business_id, df_yelp_review), index=['frnd_count','total_stars']))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:40.137023Z","iopub.execute_input":"2021-10-12T22:54:40.137459Z","iopub.status.idle":"2021-10-12T22:54:50.413138Z","shell.execute_reply.started":"2021-10-12T22:54:40.137412Z","shell.execute_reply":"2021-10-12T22:54:50.412050Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"users_ids[users_ids[\"frnd_count\"]>0]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:50.416223Z","iopub.execute_input":"2021-10-12T22:54:50.416661Z","iopub.status.idle":"2021-10-12T22:54:50.435140Z","shell.execute_reply.started":"2021-10-12T22:54:50.416616Z","shell.execute_reply":"2021-10-12T22:54:50.433949Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"# **Modelling**","metadata":{}},{"cell_type":"markdown","source":"## **Predict Rating from Review Text**","metadata":{}},{"cell_type":"code","source":"# split data\nfrom sklearn.model_selection import train_test_split\n\n# preprocessing and layer\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\n# visualisasi plot\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:50.436734Z","iopub.execute_input":"2021-10-12T22:54:50.437136Z","iopub.status.idle":"2021-10-12T22:54:50.445645Z","shell.execute_reply.started":"2021-10-12T22:54:50.437090Z","shell.execute_reply":"2021-10-12T22:54:50.444592Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"a = df_yelp_business[df_yelp_business['categories'].str.contains('Restaurant') == True]\nrev = df_yelp_review[df_yelp_review.business_id.isin(a['business_id']) == True]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:50.447242Z","iopub.execute_input":"2021-10-12T22:54:50.447686Z","iopub.status.idle":"2021-10-12T22:54:50.711722Z","shell.execute_reply.started":"2021-10-12T22:54:50.447640Z","shell.execute_reply":"2021-10-12T22:54:50.710565Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"rev_samp = rev.sample(n = 350000, random_state = 42)\ntrain = rev_samp[0:280000]\ntest = rev_samp[280000:]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:50.713018Z","iopub.execute_input":"2021-10-12T22:54:50.713361Z","iopub.status.idle":"2021-10-12T22:54:50.995233Z","shell.execute_reply.started":"2021-10-12T22:54:50.713321Z","shell.execute_reply":"2021-10-12T22:54:50.994126Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:50.996351Z","iopub.execute_input":"2021-10-12T22:54:50.996632Z","iopub.status.idle":"2021-10-12T22:54:51.002832Z","shell.execute_reply.started":"2021-10-12T22:54:50.996605Z","shell.execute_reply":"2021-10-12T22:54:51.001811Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#train = pd.read_csv('/home/adam/R/Yelp/dataset/model_train.csv', usecols = ['text', 'stars'])\ntrain = train[['text', 'stars']]\ntrain['stars'].hist();train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.004157Z","iopub.execute_input":"2021-10-12T22:54:51.004585Z","iopub.status.idle":"2021-10-12T22:54:51.246636Z","shell.execute_reply.started":"2021-10-12T22:54:51.004545Z","shell.execute_reply":"2021-10-12T22:54:51.245605Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"train = pd.get_dummies(train, columns = ['stars'])\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.248333Z","iopub.execute_input":"2021-10-12T22:54:51.248668Z","iopub.status.idle":"2021-10-12T22:54:51.307836Z","shell.execute_reply.started":"2021-10-12T22:54:51.248635Z","shell.execute_reply":"2021-10-12T22:54:51.307088Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#test = pd.read_csv('/home/adam/R/Yelp/dataset/model_test.csv', usecols=['text', 'stars'])\ntest = test[['text', 'stars']]\ntest = pd.get_dummies(test, columns = ['stars'])\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.309392Z","iopub.execute_input":"2021-10-12T22:54:51.309968Z","iopub.status.idle":"2021-10-12T22:54:51.338525Z","shell.execute_reply.started":"2021-10-12T22:54:51.309913Z","shell.execute_reply":"2021-10-12T22:54:51.337780Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# set frac = 1. to use the entire sample\ntrain_samp = train.sample(frac = .1, random_state = 42)\ntest_samp = test.sample(frac = .1, random_state = 42)\ntrain_samp.shape, test_samp.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.340063Z","iopub.execute_input":"2021-10-12T22:54:51.340429Z","iopub.status.idle":"2021-10-12T22:54:51.368066Z","shell.execute_reply.started":"2021-10-12T22:54:51.340397Z","shell.execute_reply":"2021-10-12T22:54:51.367148Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# let's see the correlation matrix\nmask = np.triu(np.ones_like(rev.corr()))\nplt.figure(figsize= (30, 10))\nsns.heatmap(rev.corr(), annot=True, cmap= 'PuBuGn', mask= mask)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.369432Z","iopub.execute_input":"2021-10-12T22:54:51.369719Z","iopub.status.idle":"2021-10-12T22:54:51.789915Z","shell.execute_reply.started":"2021-10-12T22:54:51.369691Z","shell.execute_reply":"2021-10-12T22:54:51.788971Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"**Naive Bayes Linear Model**","metadata":{}},{"cell_type":"code","source":"# max_features is an upper bound on the number of words in the vocabulary\nmax_features = 5000\ntfidf = TfidfVectorizer(max_features = max_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.791217Z","iopub.execute_input":"2021-10-12T22:54:51.791526Z","iopub.status.idle":"2021-10-12T22:54:51.795944Z","shell.execute_reply.started":"2021-10-12T22:54:51.791496Z","shell.execute_reply":"2021-10-12T22:54:51.794817Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"class NBFeatures(BaseEstimator):\n    '''Class implementation of Jeremy Howards NB Linear model'''\n    def __init__(self, alpha):\n        # Smoothing Parameter: always going to be one for my use\n        self.alpha = alpha\n        \n    def preprocess_x(self, x, r):\n        return x.multiply(r)\n    \n    # calculate probabilities\n    def pr(self, x, y_i, y):\n        p = x[y == y_i].sum(0)\n        return (p + self.alpha)/((y==y_i).sum()+self.alpha)\n    \n    # calculate the log ratio and represent as sparse matrix\n    # ie fit the nb model\n    def fit(self, x, y = None):\n        self._r = sparse.csr_matrix(np.log(self.pr(x, 1, y) /self.pr(x, 0, y)))\n        return self\n    \n    # apply the nb fit to original features x\n    def transform(self, x):\n        x_nb = self.preprocess_x(x, self._r)\n        return x_nb","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.797547Z","iopub.execute_input":"2021-10-12T22:54:51.797849Z","iopub.status.idle":"2021-10-12T22:54:51.807393Z","shell.execute_reply.started":"2021-10-12T22:54:51.797820Z","shell.execute_reply":"2021-10-12T22:54:51.806505Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# Create pipeline using sklearn pipeline:\n    # I basically create my tfidf features which are fed to my NB model \n    # for probability calculations. Then those are fed as input to my \n    # logistic regression model.\nlr = LogisticRegression(random_state=42)\nnb = NBFeatures(1)\np = Pipeline([\n    ('tfidf', tfidf),\n    ('nb', nb),\n    ('lr', lr)\n])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.808672Z","iopub.execute_input":"2021-10-12T22:54:51.809130Z","iopub.status.idle":"2021-10-12T22:54:51.824690Z","shell.execute_reply.started":"2021-10-12T22:54:51.809092Z","shell.execute_reply":"2021-10-12T22:54:51.823573Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class_names = ['stars_1', 'stars_2', 'stars_3', 'stars_4', 'stars_5']\nscores = []\npreds = np.zeros((len(test_samp), len(class_names)))\nfor i, class_name in enumerate(class_names):\n    train_target = train_samp[class_name]    \n    cv_score = np.mean(cross_val_score(estimator = p, X = train_samp['text'].values, \n                                      y = train_target, cv = 3, scoring = 'accuracy'))\n    scores.append(cv_score)\n    print('CV score for class {} is {}'.format(class_name, cv_score))\n    p.fit(train_samp['text'].values, train_target)\n    preds[:,i] = p.predict_proba(test_samp['text'].values)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:54:51.825940Z","iopub.execute_input":"2021-10-12T22:54:51.826314Z","iopub.status.idle":"2021-10-12T22:55:48.379256Z","shell.execute_reply.started":"2021-10-12T22:54:51.826267Z","shell.execute_reply":"2021-10-12T22:55:48.378401Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"train['text'][108912]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:48.380318Z","iopub.execute_input":"2021-10-12T22:55:48.380755Z","iopub.status.idle":"2021-10-12T22:55:48.396822Z","shell.execute_reply.started":"2021-10-12T22:55:48.380724Z","shell.execute_reply":"2021-10-12T22:55:48.396131Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm # estimates statistical models\nfrom sklearn.feature_selection import RFE #Recursive Feature Elimination for feature selection\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:48.397906Z","iopub.execute_input":"2021-10-12T22:55:48.398352Z","iopub.status.idle":"2021-10-12T22:55:49.443636Z","shell.execute_reply.started":"2021-10-12T22:55:48.398309Z","shell.execute_reply":"2021-10-12T22:55:49.442873Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"s = metrics.confusion_matrix(np.argmax(test_samp[class_names].values, axis = 1),np.argmax(preds, axis = 1))\nt = metrics.classification_report(np.argmax(test_samp[class_names].values, axis = 1),np.argmax(preds, axis = 1))\n\nprint(\"Test Results\")\n#pred_train = gnb.predict(X_train)\n\nprint(s)\nprint(\"\\n\")\nprint(t)\nprint(\"\\n\")\n#print(\"MAE test score:\", mean_absolute_error(np.argmax(test_samp[class_names].values, axis = 1),np.argmax(preds, axis = 1))\n#print(\"RMSE test score:\", sqrt(mean_squared_error(np.argmax(test_samp[class_names].values, axis = 1),np.argmax(preds, axis = 1))))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:49.444922Z","iopub.execute_input":"2021-10-12T22:55:49.445416Z","iopub.status.idle":"2021-10-12T22:55:49.484541Z","shell.execute_reply.started":"2021-10-12T22:55:49.445370Z","shell.execute_reply":"2021-10-12T22:55:49.483398Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"**Neural Network Model**","metadata":{}},{"cell_type":"code","source":"# Change the data type to str and numpy array \ntext = train_samp['text'].astype(str)\nlabel = train_samp[['stars_1', 'stars_2', 'stars_3', 'stars_4', 'stars_5']].values","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:49.485809Z","iopub.execute_input":"2021-10-12T22:55:49.486128Z","iopub.status.idle":"2021-10-12T22:55:49.496237Z","shell.execute_reply.started":"2021-10-12T22:55:49.486091Z","shell.execute_reply":"2021-10-12T22:55:49.495028Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"rating_train, rating_test, label_train, label_test = train_test_split(text, label, test_size = 0.3)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:49.497794Z","iopub.execute_input":"2021-10-12T22:55:49.498145Z","iopub.status.idle":"2021-10-12T22:55:49.511369Z","shell.execute_reply.started":"2021-10-12T22:55:49.498114Z","shell.execute_reply":"2021-10-12T22:55:49.510478Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# convert to sequence\ntokenizer = Tokenizer(num_words=5000, oov_token='x')\ntokenizer.fit_on_texts(rating_train) \ntokenizer.fit_on_texts(rating_test)\n \nsekuens_train = tokenizer.texts_to_sequences(rating_train)\nsekuens_test = tokenizer.texts_to_sequences(rating_test)\n \npadded_train = pad_sequences(sekuens_train) \npadded_test = pad_sequences(sekuens_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:49.512831Z","iopub.execute_input":"2021-10-12T22:55:49.513231Z","iopub.status.idle":"2021-10-12T22:55:53.174364Z","shell.execute_reply.started":"2021-10-12T22:55:49.513199Z","shell.execute_reply":"2021-10-12T22:55:53.173286Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"from keras.layers.convolutional import Conv1D","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:53.175800Z","iopub.execute_input":"2021-10-12T22:55:53.176249Z","iopub.status.idle":"2021-10-12T22:55:53.181715Z","shell.execute_reply.started":"2021-10-12T22:55:53.176205Z","shell.execute_reply":"2021-10-12T22:55:53.180596Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Embedding(input_dim=9000, output_dim=16),\n    LSTM(64),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(5, activation='softmax')\n])\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:53.183682Z","iopub.execute_input":"2021-10-12T22:55:53.184191Z","iopub.status.idle":"2021-10-12T22:55:53.728336Z","shell.execute_reply.started":"2021-10-12T22:55:53.184138Z","shell.execute_reply":"2021-10-12T22:55:53.727433Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"Adam(learning_rate=0.00146, name='Adam')\nmodel.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:53.730031Z","iopub.execute_input":"2021-10-12T22:55:53.730372Z","iopub.status.idle":"2021-10-12T22:55:53.750260Z","shell.execute_reply.started":"2021-10-12T22:55:53.730340Z","shell.execute_reply":"2021-10-12T22:55:53.749250Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):\n      print(\"\\nThe train and validation accuracy obtained has reached the value of > 90%!\")\n      self.model.stop_training = True\ncallbacks = myCallback()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:53.751550Z","iopub.execute_input":"2021-10-12T22:55:53.751876Z","iopub.status.idle":"2021-10-12T22:55:53.762754Z","shell.execute_reply.started":"2021-10-12T22:55:53.751831Z","shell.execute_reply":"2021-10-12T22:55:53.761465Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"num_epochs = 15\nhistory = model.fit(padded_train, label_train, epochs=num_epochs, validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:55:53.764056Z","iopub.execute_input":"2021-10-12T22:55:53.764384Z","iopub.status.idle":"2021-10-12T23:37:14.267593Z","shell.execute_reply.started":"2021-10-12T22:55:53.764355Z","shell.execute_reply":"2021-10-12T23:37:14.266432Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"print(\"Train Results\")\ny_pred=model.predict(padded_train) \ny_pred=np.argmax(y_pred, axis=1)\ny_train=np.argmax(label_train, axis=1)\n\nprint(confusion_matrix(y_train, y_pred))\nprint(\"\\n\")\nprint(classification_report(y_train, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T23:37:14.270147Z","iopub.execute_input":"2021-10-12T23:37:14.270607Z","iopub.status.idle":"2021-10-12T23:37:57.943378Z","shell.execute_reply.started":"2021-10-12T23:37:14.270560Z","shell.execute_reply":"2021-10-12T23:37:57.942124Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"print(\"Test Results\")\ny_pred=model.predict(padded_test) \ny_pred=np.argmax(y_pred, axis=1)\ny_test=np.argmax(label_test, axis=1)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\\n\")\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T23:37:57.945147Z","iopub.execute_input":"2021-10-12T23:37:57.945592Z","iopub.status.idle":"2021-10-12T23:38:17.394994Z","shell.execute_reply.started":"2021-10-12T23:37:57.945546Z","shell.execute_reply":"2021-10-12T23:38:17.393108Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"## **Recommendation System**","metadata":{}},{"cell_type":"code","source":"# to choose a restaurant, just copy the business id and paste it in the next cell\n# you can always rerun the cell to choose another restuarant. \ndf_yelp_business.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T23:38:17.398415Z","iopub.execute_input":"2021-10-12T23:38:17.398859Z","iopub.status.idle":"2021-10-12T23:38:17.436487Z","shell.execute_reply.started":"2021-10-12T23:38:17.398813Z","shell.execute_reply":"2021-10-12T23:38:17.435430Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"import operator\nfrom scipy.spatial.distance import cdist\n\ndef business_choose(name):\n    new_reviews = df_yelp_review.loc[df_yelp_review['business_id'] == name, 'text']\n    \n    new_categories = df_yelp_business.loc[df_yelp_business['business_id'] == name, 'categories']\n    \n    # find most similar reviews\n    dists1 = cdist(vectorizer_reviews.transform(new_reviews).todense().mean(axis=0), \n              vectorized_reviews.T.dot(businessxreview).T.todense(), \n               metric='correlation')\n    \n    # find most similar categories\n    dists2 = cdist(vectorizer_categories.transform(new_categories).todense().mean(axis=0), \n              vectorized_categories.todense(), \n               metric='correlation')\n    \n    # combine the two vectors in one matrix\n    dists_together = np.vstack([dists1.ravel(), dists2.ravel()]).T\n    \n    # this is a key cell: how are we going to prioritize ?\n    dists = dists_together.mean(axis=1)\n    \n    # select the closest 10\n    closest = dists.argsort().ravel()[:10]\n    \n    display('Selected Business => ',df_yelp_business.loc[df_yelp_business['business_id']== name, ['business_id', 'categories', 'name', 'stars']])\n    \n    display('Recomended Business => ',df_yelp_business.loc[df_yelp_business['business_id'].isin(df_yelp_business['business_id'].iloc[closest]), ['business_id', 'categories', 'name', 'stars']])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T23:38:17.437830Z","iopub.execute_input":"2021-10-12T23:38:17.438160Z","iopub.status.idle":"2021-10-12T23:38:17.449036Z","shell.execute_reply.started":"2021-10-12T23:38:17.438127Z","shell.execute_reply":"2021-10-12T23:38:17.447983Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"business_choose('0agr_FyDdcMQtv-JCLOnhg')","metadata":{"execution":{"iopub.status.busy":"2021-10-12T23:38:17.450209Z","iopub.execute_input":"2021-10-12T23:38:17.450597Z","iopub.status.idle":"2021-10-12T23:38:20.118431Z","shell.execute_reply.started":"2021-10-12T23:38:17.450565Z","shell.execute_reply":"2021-10-12T23:38:20.117372Z"},"trusted":true},"execution_count":94,"outputs":[]}]}